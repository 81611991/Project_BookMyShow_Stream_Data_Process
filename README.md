# BookMyShow Online Ticket Booking Stream Data Processing

## Project Overview

This project demonstrates a real-time stream data processing pipeline for an online ticket booking system using Azure services. The architecture ingests booking and payment events, processes them using Azure Stream Analytics, and stores the results in a Synapse Data Warehouse for analysis and reporting.

## Tech Stack

* **Azure Event Hub:** Ingests booking and payment events in real-time.
* **Azure Stream Analytics:** Processes the incoming event streams, performs transformations, aggregations, and joins.
* **Azure Synapse Data Warehouse:** Stores the processed data for analysis and reporting.
* **Programming Languages:** Python (for event generation), SQL (for Stream Analytics queries and Synapse DWH).

## Project Components

1. **Event Hub Setup:**
    * Created two Event Hubs: `bookingsstopic` and `paymentstopic` to ingest booking and payment events, respectively.
    * Configured SAS policies for secure access.

2. **Data Generation:**
    * Developed Python scripts (`mock_bookings.py` and `mock_payments.py`) to generate mock booking and payment events and publish them to the respective Event Hubs.

3. **Stream Analytics Job:**
    * Created a Stream Analytics job (`devansh_gds_stream_analysis`) to process the incoming event streams.
    * Configured inputs to read from the `bookingsstopic` and `paymentstopic` Event Hubs.
    * Configured output to write the processed data to the Synapse Data Warehouse.
    * Defined SQL-like queries to perform real-time processing, transformations, and aggregations.
    

4. **Synapse Data Warehouse:**
    * Created a Synapse workspace (`bookmyshowsynapse`) with a dedicated SQL pool (`bookmyshow-dwh`)
    * Defined a schema (`bookymyshow`) and table (`bookings_fact`) to store the processed data.

## Data Flow

1. Mock booking and payment events are generated by Python scripts.
2. Events are ingested into respective Event Hubs (`bookingsstopic` and `paymentstopic`).
3. Azure Stream Analytics job processes the event streams in real-time.
4. Processed data is written to the Synapse Data Warehouse (`bookmyshow-dwh`).

## Deployment

1. Deploy the Azure Event Hubs namespace and configure SAS policies.
2. Create the Synapse workspace and dedicated SQL pool.
3. Develop and deploy the Stream Analytics job with appropriate inputs, queries, and outputs.
4. Configure the Python scripts with Event Hub connection strings and run them to generate mock events.

## Running the Project

1. Execute the Python scripts to start generating mock booking and payment events.
2. Monitor the Stream Analytics job to observe real-time processing.
3. Query the Synapse Data Warehouse to analyze the processed data.

## Notes

* This project uses mock data for demonstration purposes. For production, integrate with actual booking and payment systems.
* The Stream Analytics job can be further customized to perform more complex processing and aggregations.
* The Synapse Data Warehouse can be scaled based on data volume and query requirements.

Feel free to contribute to this project by adding more features, improving the data processing logic, or enhancing the documentation.